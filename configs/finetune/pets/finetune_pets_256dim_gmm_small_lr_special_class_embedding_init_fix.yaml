data:
  type: image
  train_dir: data/Oxford-IIIT-Pet
  test_dir: data/Oxford-IIIT-Pet
  lsun_categories_train: null
  lsun_categories_test: null
  img_size: 128
  nlabels: 1
generator:
  name: resnet2
  kwargs:
    nfilter: 64
    nfilter_max: 1024
    embed_size: 256
discriminator:
  name: resnet2
  kwargs:
    nfilter: 64
    nfilter_max: 1024
    embed_size: 256
z_dist:
  type: gmm
  dim: 256
  gmm_components_weight: output/vec2img/pets_256dim_special_init_fix/gmm_components_weights.npy
  gmm_mean: output/vec2img/pets_256dim_special_init_fix/gmm_mean.npy
  gmm_cov: output/vec2img/pets_256dim_special_init_fix/gmm_cov.npy
training:
  batch_size: 32
  change_generator_embedding_layer: true
  change_discriminator_fc_layer: true
  pretrain_ckpt_file: null
  generator_pretrained_ckpt_file: output/vec2img/pets_256dim_special_init_fix/chkpts/generator.pth
  discriminator_pretrained_ckpt_file: ./pretrained_ckpt/imagenet/imagenet-8c505f47.pt
  finetune: true
  out_dir: output/finetune/pets_256dim_gmm_small_lr_special_init_fix
  inception_every: -1
  fid_every: 1000
  fid_fake_imgs_num: 8000
  lr_g: 0.000025
  lr_d: 0.000025
test:
  model_file: 'model.pt'
  batch_size: 32 
  sample_size: 64 
  sample_nrow: 8
  compute_inception: false
  compute_fid: true
  fid_fake_imgs_num: 8000
