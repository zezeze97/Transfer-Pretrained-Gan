data:
  type: image
  train_dir: data/cars_train
  test_dir: data/cars_train
  lsun_categories_train: [kitchen_train]
  lsun_categories_test: [kitchen_val]
  img_size: 128
  nlabels: 1
generator:
  name: resnet2
  kwargs:
    nfilter: 64
    nfilter_max: 1024
    embed_size: 256
discriminator:
  name: resnet2
  kwargs:
    nfilter: 64
    nfilter_max: 1024
    embed_size: 256
z_dist:
  type: gmm
  dim: 256
  gmm_components_weight: output/vec2img/cars_256dim_special_init_fix/gmm_components_weights.npy
  gmm_mean: output/vec2img/cars_256dim_special_init_fix/gmm_mean.npy
  gmm_cov: output/vec2img/cars_256dim_special_init_fix/gmm_cov.npy
training:
  batch_size: 32
  change_generator_embedding_layer: true
  change_discriminator_fc_layer: true
  pretrain_ckpt_file: null
  generator_pretrained_ckpt_file: output/vec2img/cars_256dim_special_init_fix/chkpts/generator.pth
  discriminator_pretrained_ckpt_file: ./pretrained_ckpt/imagenet/imagenet-8c505f47.pt
  finetune: true
  out_dir: output/finetune/cars_256dim_gmm_small_lr_special_init_fix_frozen_g_d
  inception_every: -1
  fid_every: 1000
  fid_fake_imgs_num: 8000
  lr_g: 0.000025
  lr_d: 0.000025
  frozen_generator: true
  frozen_discriminator: true
  frozen_generator_param_list: ['resnet_3_0.conv_0.weight', 'resnet_3_0.conv_0.bias', 'resnet_3_0.conv_1.weight', 'resnet_3_0.conv_1.bias', 'resnet_3_0.conv_s.weight', 'resnet_3_1.conv_0.weight', 'resnet_3_1.conv_0.bias', 'resnet_3_1.conv_1.weight', 'resnet_3_1.conv_1.bias', 'resnet_4_0.conv_0.weight', 'resnet_4_0.conv_0.bias', 'resnet_4_0.conv_1.weight', 'resnet_4_0.conv_1.bias', 'resnet_4_0.conv_s.weight', 'resnet_4_1.conv_0.weight', 'resnet_4_1.conv_0.bias', 'resnet_4_1.conv_1.weight', 'resnet_4_1.conv_1.bias', 'resnet_5_0.conv_0.weight', 'resnet_5_0.conv_0.bias', 'resnet_5_0.conv_1.weight', 'resnet_5_0.conv_1.bias', 'resnet_5_0.conv_s.weight', 'resnet_5_1.conv_0.weight', 'resnet_5_1.conv_0.bias', 'resnet_5_1.conv_1.weight', 'resnet_5_1.conv_1.bias','conv_img.weight', 'conv_img.bias']
  frozen_discriminator_param_list: ['conv_img.weight', 'conv_img.bias', 'resnet_0_0.conv_0.weight', 'resnet_0_0.conv_0.bias', 'resnet_0_0.conv_1.weight', 'resnet_0_0.conv_1.bias', 'resnet_0_1.conv_0.weight', 'resnet_0_1.conv_0.bias', 'resnet_0_1.conv_1.weight', 'resnet_0_1.conv_1.bias', 'resnet_0_1.conv_s.weight']
test:
  model_file: 'model.pt'
  batch_size: 32 
  sample_size: 64 
  sample_nrow: 8
  compute_inception: false
  compute_fid: true
  fid_fake_imgs_num: 8000
